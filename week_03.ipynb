{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 분석 수행 과정**\n",
        "1. **load dataset**\n",
        "2. **set X, y**\n",
        "  - X - 설명변수\n",
        "  - y - 종속변수\n",
        "3. **check data**\n",
        "  - **X.info()**\n",
        "    - 데이터 개수\n",
        "    - 컬럼 개수\n",
        "    - 결측 데이터 존재 유무\n",
        "    - 데이터 타입\n",
        "  - **X.describe()**\n",
        "    - 데이터 개수\n",
        "    - 평균\n",
        "    - 표준편차\n",
        "    - 최솟값\n",
        "    - 최댓값\n",
        "    - 4분위 수\n",
        "    - 스케일(값의 범위)을 중점적으로 체크!\n",
        "    - 컬럼 별 스케일 오차가 발생하는 경우 전처리 필요!\n",
        "  - **y.value_counts()**\n",
        "    - 각 범주별 데이터 개수 \n",
        "  - **y.value_counts() / len(y)**\n",
        "    - 각 범주별 데이터 개수 비율\n",
        "    - 너무 적은 데이터 => 오버 샘플링\n",
        "    - 너무 많은 데이터 => 언더 샘플링\n",
        "4. **split data**\n",
        "  - 머신러닝\n",
        "    - 학습:테스트 = 8:2\n",
        "  - 딥러닝\n",
        "    - 학습:검증:테스트 = 6:2:2\n",
        "    - 부분 배치 학습을 수행하며 점진적으로 학습량을 늘려가는 경우가 많음\n",
        "    - 중간 점검의 의미로 검증 데이터를 활용 \n",
        "  - **train_test_split(X, y, test_size, train_size, shuffle, stratify...)**\n",
        "    - ```python\n",
        "      from sklearn.model_selection import train_test_split\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "    ``` \n",
        "    - X - 설명변수\n",
        "    - y - 종속변수\n",
        "    - test_size - 테스트 데이터 비율\n",
        "    - train_size - 학습 데이터 비율\n",
        "    - shuffle - 데이터 셔플 여부\n",
        "    - stratify - 범주형 데이터를 다룰 때 중요한 옵션으로, 종속 변수를 넣음으로써 클래스 비율을 유지\n",
        "5. **preprocess data**\n",
        "  - 스케일 처리\n",
        "    - MinMaxScaler\n",
        "    - StandardScaler\n",
        "    - RobustScaler\n",
        "  - 인코딩 처리\n",
        "    - LabelEncoder\n",
        "    - OrdinalEncoder\n",
        "    - OnehotEncoder\n",
        "  - 차원 축소\n",
        "  - feature engineering \n",
        "6. **build model**\n",
        "  - 모델 생성\n",
        "  - 모델 학습\n",
        "    - fit(X, y)\n",
        "  - 모델 평가\n",
        "    - score(X, y)\n",
        "    - 분류 모델\n",
        "      - 정확도를 반환\n",
        "    - 회귀 모델\n",
        "      - R2 Score를 반환 \n",
        "  - 모델 예측\n",
        "    - predict(X) "
      ],
      "metadata": {
        "id": "E4L9ikAmmrtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**최근접 이웃 알고리즘 모델**\n",
        "  - **KNeighborsClassifier(n_neighbors=5...)**\n",
        "    - ```python\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    model = KNeighborsClassifier(n_neighbors=10)\n",
        "    ```\n",
        "    - 분류를 알 수 없는 데이터에 대하여, k개의 이웃 데이터 분류를 확인한 후 다수결에 의해 분류를 결정 \n",
        "  -  **KNeighborsRegressor(n_neighbors=5...)**\n",
        "    - ```python\n",
        "    from sklearn.neighbors import KNeighborsRegressor\n",
        "    model = KNeighborsRegressor(n_neighbors=10)\n",
        "    ```\n",
        "    - 값을 알 수 없는 데이터에 대하여, k개의 이웃 데이터 값을 확인한 후 평균 값으로 값을 결정 \n",
        "  - 단점\n",
        "    - 학습에 사용된 데이터 범위 내에서만 예측 가능 \n",
        "  - 주의 사항\n",
        "    - `k가 너무 큰 경우` => `과소적합 발생`\n",
        "    - `k가 너무 작은 경우` => `과적합 발생`"
      ],
      "metadata": {
        "id": "T9QCB88VvrxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 01 - 데이터 분석 수행 과정 with KNeighborsClassifier"
      ],
      "metadata": {
        "id": "5qSoWd1Om3h7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gMLkqf08kkmH"
      },
      "outputs": [],
      "source": [
        "# import numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.options.display.max_columns = 5\n",
        "pd.options.display.max_rows = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. load dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "ls4JFmxFuoG5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. set X, y\n",
        "X = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "y = pd.Series(data=data.target)\n",
        "\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFOGYsonukge",
        "outputId": "60520e2d-5a41-4b73-f367-b1fd55023407"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
            "0        17.99         10.38  ...          0.4601                  0.11890\n",
            "1        20.57         17.77  ...          0.2750                  0.08902\n",
            "2        19.69         21.25  ...          0.3613                  0.08758\n",
            "3        11.42         20.38  ...          0.6638                  0.17300\n",
            "4        20.29         14.34  ...          0.2364                  0.07678\n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. check X, y\n",
        "print(X.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Ix7YJQpEIF",
        "outputId": "8febecff-a4f7-480f-bb77-103277fc7433"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsxOVhcYpMGV",
        "outputId": "4415fcae-88e9-48a4-8393-c7c9fe19f465"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
            "count   569.000000    569.000000  ...      569.000000               569.000000\n",
            "mean     14.127292     19.289649  ...        0.290076                 0.083946\n",
            "std       3.524049      4.301036  ...        0.061867                 0.018061\n",
            "min       6.981000      9.710000  ...        0.156500                 0.055040\n",
            "25%      11.700000     16.170000  ...        0.250400                 0.071460\n",
            "50%      13.370000     18.840000  ...        0.282200                 0.080040\n",
            "75%      15.780000     21.800000  ...        0.317900                 0.092080\n",
            "max      28.110000     39.280000  ...        0.663800                 0.207500\n",
            "\n",
            "[8 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK2TiFpbpMLE",
        "outputId": "ae8084b9-9155-46e2-e325-24b79051bbf9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    357\n",
            "0    212\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.value_counts() / len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkCLBC_YpMPd",
        "outputId": "cb63e957-28a2-4f59-b6ea-653a6ff50919"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    0.627417\n",
            "0    0.372583\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "print(len(X_train), len(X_test))\n",
        "print(len(y_train), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTeyQRKjsqAz",
        "outputId": "0917dfff-b687-4a33-e294-5e3c01467da0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455 114\n",
            "455 114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. preprocess data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(X_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE3PnXi-tvh8",
        "outputId": "9cfcabf3-f0b8-42a3-e88c-78adfefb741a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.27303706 0.23638823 0.26756962 0.14858961 0.5404893  0.28317281\n",
            "  0.09090909 0.14885686 0.53535354 0.35531775 0.09846098 0.14206153\n",
            "  0.08126892 0.04075099 0.19702893 0.10032445 0.04992424 0.17425649\n",
            "  0.14307424 0.09446126 0.23194593 0.27660785 0.21524976 0.10786964\n",
            "  0.50406128 0.16552668 0.12162393 0.27646048 0.3578047  0.20024925]\n",
            " [0.09555587 0.1586067  0.08686338 0.04360551 0.1572628  0.03613275\n",
            "  0.00862465 0.01725646 0.36767677 0.4011793  0.0228499  0.20880481\n",
            "  0.01756834 0.00557903 0.19294965 0.01975997 0.00929545 0.06577003\n",
            "  0.26915067 0.04346835 0.06293134 0.22908367 0.05224364 0.024651\n",
            "  0.18120584 0.02428423 0.0125812  0.04773196 0.33879781 0.15085924]\n",
            " [0.27398362 0.39567129 0.26418354 0.15435843 0.31470615 0.14302804\n",
            "  0.07291471 0.14234592 0.32020202 0.28193929 0.22437081 0.30670969\n",
            "  0.20494516 0.08750126 0.09715471 0.11752336 0.05494949 0.33282819\n",
            "  0.363708   0.17205616 0.20704376 0.32669323 0.19239006 0.09690818\n",
            "  0.14997028 0.06062811 0.04432479 0.16402062 0.14587788 0.08966286]\n",
            " [0.29764778 0.24721001 0.28166678 0.17090138 0.28726189 0.09373658\n",
            "  0.08327085 0.12206759 0.22020202 0.14806726 0.06561651 0.11724275\n",
            "  0.06000396 0.03339198 0.14681987 0.06600174 0.05704545 0.17156658\n",
            "  0.09762481 0.05531833 0.25649235 0.32953899 0.24119727 0.12868659\n",
            "  0.37264743 0.10071698 0.15264957 0.33257732 0.22356854 0.13898728]\n",
            " [0.41312888 0.14271221 0.40225278 0.26222694 0.37907376 0.23078339\n",
            "  0.16717432 0.29488072 0.38181818 0.15876829 0.07249683 0.10062323\n",
            "  0.05660911 0.03948091 0.1191148  0.09686965 0.04237374 0.24019701\n",
            "  0.12393764 0.04958335 0.34044824 0.20574843 0.31819314 0.18128195\n",
            "  0.33764776 0.16261606 0.14606838 0.47216495 0.27512473 0.10278106]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. build model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "score = model.score(X_train, y_train)\n",
        "print(f'SCORE(TRAIN): {score}')\n",
        "\n",
        "score = model.score(X_test, y_test)\n",
        "print(f' SCORE(TEST): {score}\\n')\n",
        "\n",
        "pred = model.predict(X_test[:10])\n",
        "print(f'PREDICT: {pred}')\n",
        "print(f' ANSWER: {y_test[:10].values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqcA41Fxuzq3",
        "outputId": "55ffccc5-6704-4ab7-9d8f-035d38632d07"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCORE(TRAIN): 0.978021978021978\n",
            " SCORE(TEST): 0.9473684210526315\n",
            "\n",
            "PREDICT: [1 0 1 1 1 1 1 0 1 1]\n",
            " ANSWER: [1 0 1 1 1 1 1 0 1 1]\n"
          ]
        }
      ]
    }
  ]
}